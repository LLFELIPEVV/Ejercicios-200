# Ejercicio 5: Clasificador binario para saber si un punto est√° sobre o por encima de la recta y = 2x + 3

import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings

warnings.filterwarnings(
    "ignore"
)  # Opcional: ocultar advertencias si est√°s en modo presentaci√≥n o pruebas

# ---------------------------------------------
# 1. Generaci√≥n del dataset sint√©tico
# ---------------------------------------------

# Creamos 100.000 puntos aleatorios en el plano (x, y), entre 0 y 10
X = np.random.rand(100000, 2) * 10

# Separamos las coordenadas x e y para trabajar m√°s c√≥modamente
x_vals = X[:, 0]
y_vals = X[:, 1]

# Regla de clasificaci√≥n:
# Clase 1 ‚Üí si el punto est√° por encima de la l√≠nea y = 2x + 3
# Clase 0 ‚Üí si est√° por debajo o sobre la l√≠nea
y = (y_vals > 2 * x_vals + 3).astype(int)

# ---------------------------------------------
# 2. Escalado de caracter√≠sticas (normalizaci√≥n)
# ---------------------------------------------

# Escalamos los valores entre 0 y 1 para mejorar el rendimiento del modelo
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# ---------------------------------------------
# 3. Divisi√≥n del dataset
# ---------------------------------------------

# Dividimos en 80% entrenamiento y 20% test. Stratify asegura proporci√≥n balanceada de clases.
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# ---------------------------------------------
# 4. Creaci√≥n y entrenamiento del modelo
# ---------------------------------------------

# Usamos regresi√≥n log√≠stica (modelo lineal) para clasificaci√≥n binaria
model = LogisticRegression(
    solver="lbfgs",  # optimizador eficiente recomendado por sklearn
    max_iter=2000,  # iteraciones suficientes para asegurar convergencia
    random_state=42,
)
model.fit(X_train, y_train)

# ---------------------------------------------
# 5. Evaluaci√≥n del modelo
# ---------------------------------------------

# Realizamos predicciones sobre el conjunto de prueba
y_pred = model.predict(X_test)

# M√©trica de precisi√≥n global (accuracy)
acc = accuracy_score(y_test, y_pred)
print(f"\n‚úÖ Accuracy del modelo: {acc:.4f}")

# Reporte detallado: precisi√≥n, recall, F1-score por clase
print("\nüìã Reporte de clasificaci√≥n:")
print(
    classification_report(
        y_test, y_pred, target_names=["Abajo/Sobre la l√≠nea", "Encima de la l√≠nea"]
    )
)

# Matriz de confusi√≥n: muestra cu√°ntos aciertos y errores hubo por clase
print("\nüìä Matriz de confusi√≥n:")
print(confusion_matrix(y_test, y_pred))

# ---------------------------------------------
# 6. Pruebas manuales con nuevos puntos
# ---------------------------------------------

print("\nüîç Predicciones manuales:")

# Lista de puntos a probar manualmente
ejemplos = [(2, 9), (1, 4), (3, 3), (5, 14)]

# Iteramos y clasificamos cada punto
for punto in ejemplos:
    punto_scaled = scaler.transform(
        [punto]
    )  # Escalamos igual que los datos de entrenamiento
    pred = model.predict(punto_scaled)[0]  # Obtenemos la predicci√≥n (0 o 1)
    etiqueta = "Encima de la l√≠nea" if pred == 1 else "Abajo o sobre la l√≠nea"
    print(f"Punto {punto} ‚Üí Clase predicha: {pred} ({etiqueta})")
