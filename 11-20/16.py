# Ejercicio 16: üå∏ Clasificaci√≥n de puntos dentro de una flor polar usando una Red Neuronal MLP

import numpy as np
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


def generar_datos_flor_polar(n=100_000, centro=(0, 0), escala=1.0, petalos=6):
    """
    Genera puntos distribuidos aleatoriamente y clasifica si est√°n dentro de una flor polar.
    F√≥rmula de la flor: r(Œ∏) = 1 + 0.5 * cos(kŒ∏), donde k = n√∫mero de p√©talos.

    Par√°metros:
        n (int): N√∫mero de puntos a generar.
        centro (tuple): Coordenadas del centro de la flor (x, y).
        escala (float): Factor de escala para el tama√±o de la flor.
        petalos (int): N√∫mero de p√©talos que tendr√° la flor.

    Retorna:
        X (ndarray): Coordenadas (x1, x2) de cada punto.
        y (ndarray): Etiquetas binarias (1 si est√° dentro de la flor, 0 si est√° fuera).
    """
    if petalos < 1 or n < 1:
        raise ValueError("El n√∫mero de puntos y de p√©talos debe ser positivo.")

    # Generar puntos aleatorios en un cuadrado centrado en el origen
    X = (np.random.rand(n, 2) * 2 - 1) * escala * 3
    x, y_coord = X[:, 0] - centro[0], X[:, 1] - centro[1]

    # Convertir a coordenadas polares
    r = np.sqrt(x**2 + y_coord**2)
    theta = np.arctan2(y_coord, x)
    theta = np.mod(theta, 2 * np.pi)

    # Definir radio de la flor en funci√≥n de theta
    radio_flor = 1 + 0.5 * np.cos(petalos * theta)

    # Etiqueta 1 si el punto est√° dentro del contorno de la flor
    esta_dentro = r < radio_flor * escala
    return X, esta_dentro.astype(int)


# üîπ Paso 1: Generar los datos
X, y = generar_datos_flor_polar(n=200_000, centro=(0, 0), escala=2.5, petalos=6)

# üîπ Paso 2: Escalar caracter√≠sticas entre 0 y 1
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# üîπ Paso 3: Dividir en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# üîπ Paso 4: Construcci√≥n del modelo (Red Neuronal Multicapa)
model = MLPClassifier(
    hidden_layer_sizes=(64, 64),
    activation="relu",  # Activaci√≥n no lineal para aprender patrones complejos
    solver="adam",  # Optimizador eficiente y ampliamente utilizado
    max_iter=3000,  # Iteraciones suficientes para converger
    random_state=42,
)

# üîπ Paso 5: Entrenar el modelo
model.fit(X_train, y_train)

# üîπ Paso 6: Evaluar el desempe√±o del modelo
y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)

print(f"\n‚úÖ Accuracy del modelo: {acc:.4f}")

print("\nüìã Reporte de clasificaci√≥n:")
print(
    classification_report(
        y_test, y_pred, target_names=["Fuera de la flor", "Dentro de la flor"]
    )
)

print("\nüìä Matriz de confusi√≥n:")
print(confusion_matrix(y_test, y_pred))

# üîπ Paso 7: Visualizaci√≥n gr√°fica de la clasificaci√≥n
plt.figure(figsize=(8, 8))
colores = ["red" if pred == 0 else "green" for pred in y_pred]

plt.scatter(X_test[:, 0], X_test[:, 1], c=colores, s=10, edgecolors="k", alpha=0.5)

plt.title("Clasificaci√≥n de puntos dentro de una flor polar - Red Neuronal")
plt.xlabel("x1 (horizontal)")
plt.ylabel("x2 (vertical)")
plt.grid(True)
plt.tight_layout()
plt.show()
