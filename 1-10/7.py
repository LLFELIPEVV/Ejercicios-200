# Ejercicio 7 Profesional: Clasificador con red neuronal (MLPClassifier)
# Objetivo: Aprender a clasificar si un punto (x, y) est√° dentro o fuera de un c√≠rculo.

import numpy as np
import matplotlib.pyplot as plt
import warnings

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

warnings.filterwarnings("ignore")  # Opcional: suprime warnings innecesarios

# -------------------------------------------------
# 1. Generaci√≥n del dataset sint√©tico
# -------------------------------------------------

# Creamos 100.000 puntos aleatorios dentro de un cuadrado de 10x10
X = np.random.rand(100000, 2) * 10

# Definimos un c√≠rculo de centro (5,5) y radio 3
cx, cy = 5, 5
r = 3

# Calculamos la distancia cuadrada desde cada punto al centro del c√≠rculo
distancia_cuadrada = (X[:, 0] - cx) ** 2 + (X[:, 1] - cy) ** 2

# Asignamos etiqueta 1 si est√° dentro del c√≠rculo, 0 si est√° fuera
y = (distancia_cuadrada < r**2).astype(int)

# -------------------------------------------------
# 2. Preprocesamiento: Escalado de caracter√≠sticas
# -------------------------------------------------

# Normalizamos los datos entre 0 y 1 (obligatorio para redes neuronales)
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# -------------------------------------------------
# 3. Divisi√≥n del dataset
# -------------------------------------------------

# Separamos datos en entrenamiento y prueba (80/20)
# Usamos stratify para mantener el equilibrio entre clases
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# -------------------------------------------------
# 4. Entrenamiento de la Red Neuronal
# -------------------------------------------------

model = MLPClassifier(
    hidden_layer_sizes=(30, 30),  # 2 capas ocultas con 30 neuronas cada una
    activation="relu",  # Funci√≥n de activaci√≥n no lineal
    solver="adam",  # Optimizador moderno basado en gradiente
    max_iter=1000,  # Iteraciones para asegurar convergencia
    random_state=42,
)

# Entrenamos el modelo con los datos normalizados
model.fit(X_train, y_train)

# -------------------------------------------------
# 5. Evaluaci√≥n del modelo
# -------------------------------------------------

# Predicci√≥n sobre los datos de prueba
y_pred = model.predict(X_test)

# M√©tricas de rendimiento
acc = accuracy_score(y_test, y_pred)
print(f"\n‚úÖ Accuracy del modelo (Red Neuronal): {acc:.4f}")

print("\nüìã Reporte de clasificaci√≥n:")
print(
    classification_report(
        y_test, y_pred, target_names=["Fuera del c√≠rculo", "Dentro del c√≠rculo"]
    )
)

print("\nüìä Matriz de confusi√≥n:")
print(confusion_matrix(y_test, y_pred))

# -------------------------------------------------
# 6. Predicciones manuales
# -------------------------------------------------

print("\nüîç Predicciones para puntos manuales:")
ejemplos = [(5, 5), (2, 2), (8, 5), (5, 2), (6, 8)]

for punto in ejemplos:
    punto_scaled = scaler.transform([punto])  # Usar transform, no fit_transform
    pred = model.predict(punto_scaled)[0]
    etiqueta = "Dentro del c√≠rculo" if pred == 1 else "Fuera del c√≠rculo"
    print(f"Punto {punto} ‚Üí Clase predicha: {pred} ({etiqueta})")

# -------------------------------------------------
# 7. Visualizaci√≥n: Datos + C√≠rculo + Puntos manuales
# -------------------------------------------------

# Para graficar, desnormalizamos los datos a su escala original
X_test_original = scaler.inverse_transform(X_test)

# Colores por clase: azul = fuera, rojo = dentro
plt.figure(figsize=(8, 8))
plt.scatter(
    X_test_original[:, 0],
    X_test_original[:, 1],
    c=y_pred,
    cmap="coolwarm",
    alpha=0.4,
    edgecolors="none",
    s=10,
    label="Predicci√≥n del modelo",
)

# Dibuja el c√≠rculo real (para comparar con la predicci√≥n)
circle = plt.Circle((cx, cy), r, color="black", fill=False, linestyle="--", linewidth=2)
plt.gca().add_patch(circle)

# Puntos de prueba manual
for punto in ejemplos:
    plt.plot(punto[0], punto[1], "ko", markersize=8, label="Punto manual")

plt.title(
    "üîµ Clasificaci√≥n de puntos por red neuronal\n(C√≠rculo centro (5,5), radio=3)"
)
plt.xlabel("X")
plt.ylabel("Y")
plt.grid(True)
plt.axis("equal")
plt.legend(["C√≠rculo real", "Puntos manuales"])
plt.show()
