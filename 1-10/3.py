# Ejercicio 3 mejorado: Clasificador para predecir si x1 > x2
import numpy as np

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# =========================
# 1. Generaci√≥n de datos
# =========================

# Creamos 100,000 pares de n√∫meros aleatorios entre 0 y 10
X = np.random.rand(100000, 2) * 10

# Creamos la variable objetivo (y)
# y ser√° 1 si x1 > x2, y 0 si x1 <= x2
y = (X[:, 0] > X[:, 1]).astype(int)

# =========================
# 2. Normalizaci√≥n
# =========================

# Las redes y modelos lineales funcionan mejor si los datos est√°n entre 0 y 1
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# =========================
# 3. Divisi√≥n en entrenamiento y prueba
# =========================

# Dividimos los datos: 80% para entrenar y 20% para probar
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# =========================
# 4. Entrenamiento del modelo
# =========================

# Creamos y entrenamos el modelo de clasificaci√≥n log√≠stica
model = LogisticRegression()
model.fit(X_train, y_train)

# =========================
# 5. Evaluaci√≥n del modelo
# =========================

# Predecimos las etiquetas de prueba
y_pred = model.predict(X_test)

# M√©trica principal para clasificaci√≥n: exactitud (accuracy)
acc = accuracy_score(y_test, y_pred)
print(f"\n‚úÖ Accuracy en test: {acc:.4f}")

# Mostramos la matriz de confusi√≥n
print("\nüìä Matriz de confusi√≥n:")
print(confusion_matrix(y_test, y_pred))

# Mostramos un reporte completo: precisi√≥n, recall, F1
print("\nüìã Reporte de clasificaci√≥n:")
print(classification_report(y_test, y_pred))

# Mostramos los coeficientes (pesos) que aprendi√≥ el modelo
print("üìà Coeficientes:", model.coef_)
print("üìà Intercepto (bias):", model.intercept_)

# =========================
# 6. Predicciones sobre entradas conocidas
# =========================

print("\nüîç Predicciones en casos espec√≠ficos:")
ejemplos = [(2, 3), (9, 2), (5, 5)]

for d in ejemplos:
    real = int(d[0] > d[1])  # Valor real
    d_scaled = scaler.transform([d])  # Escalamos antes de predecir
    pred = model.predict(d_scaled)[0]  # Predicci√≥n
    print(f"Entrada {d} ‚Üí ¬øx1 > x2?: {real}, predicci√≥n del modelo: {pred}")
